{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linzhi0918/deliberative-politics/blob/main/notebooks/Revised_02_Deliberation_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This codebook was run in Google Colab"
      ],
      "metadata": {
        "id": "4GCt3XMr6ddz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRIY8qS16efX",
        "outputId": "169d97a4-f07d-44f4-b4ad-968e8cc8c091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL1OEU5R6aB3"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/data/sample2.csv\"\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/data'     # You'll get 2 directories here, one will have the results and one will have CSVs with extracted features\n",
        "\n",
        "X_col = 'text'  # Name of X column (string)\n",
        "y_col = 'label'        # Name of y column (0/1)\n",
        "\n",
        "# Only harbingers and politeness features are extracted in the last section (not liwc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA-8QbA86aB5"
      },
      "source": [
        "# Setting up shop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1rMEnwA6aB7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "MODIFIED_DATA = os.path.join(OUTPUT_DIR, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/data/modified_data')\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_DIR, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/data/results')\n",
        "os.makedirs(MODIFIED_DATA, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQolGGac6aB7"
      },
      "outputs": [],
      "source": [
        "nlp = English()\n",
        "\n",
        "def is_number(tok):\n",
        "    try:\n",
        "        float(tok)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def spacy_tokenizer(text):\n",
        "    return [tok.text if not is_number(tok.text) else '_NUM_' for tok in nlp(text)]\n",
        "\n",
        "def update_metrics(report, y_test, y_pred, minority_class):\n",
        "    report[0] += metrics.accuracy_score(y_test, y_pred)\n",
        "    report[1] += metrics.f1_score(y_test, y_pred)\n",
        "    report[2] += metrics.precision_score(y_test, y_pred)\n",
        "    report[3] += metrics.recall_score(y_test, y_pred)\n",
        "    report[4] += metrics.f1_score(y_test, y_pred, average='macro')\n",
        "    temp = classification_report(y_test, y_pred, output_dict=True)\n",
        "    key = str(minority_class)\n",
        "    if key not in temp:\n",
        "        key += '.0'\n",
        "    report[5] += temp[key]['f1-score']\n",
        "    return report\n",
        "\n",
        "def sklearn_models(df, X_col, y_col, OUTPUT_PATH, generate_Xy, folds=10):\n",
        "\n",
        "    df = df[df[y_col].notna()]\n",
        "    kfold = StratifiedKFold(folds, shuffle=True, random_state=1)\n",
        "    report = []\n",
        "    vc = dict(df[y_col].value_counts())\n",
        "    minority_class = min(vc, key=vc.get)\n",
        "\n",
        "    classifiers = {\n",
        "                 'logreg': LogisticRegression(class_weight='balanced'),\n",
        "                'knn': KNeighborsClassifier(),\n",
        "                'gaussianNB': GaussianNB(),\n",
        "                'bernoulliNB': BernoulliNB(),\n",
        "                'adaboost': AdaBoostClassifier(),\n",
        "                'gradient-boosting': GradientBoostingClassifier(),\n",
        "                'dec-tree': DecisionTreeClassifier(),\n",
        "                'linear-svc': LinearSVC(class_weight='balanced'),\n",
        "                'c-svc': SVC(class_weight='balanced')\n",
        "                }\n",
        "\n",
        "\n",
        "    for method, clf in classifiers.items():\n",
        "        running_report = [0]*6\n",
        "        for train_idx, test_idx in kfold.split(df, df[y_col]):\n",
        "            train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "            X_train, y_train, X_test, y_test = generate_Xy(train, test, X_col=X_col, y_col=y_col, method=method)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            running_report = update_metrics(running_report, y_test, y_pred, minority_class)\n",
        "\n",
        "        report.append([method] + [x / folds for x in running_report])\n",
        "        print(method, 'done!')\n",
        "    report = pd.DataFrame(report, columns = ['method', 'accuracy', 'f1', 'precision', 'recall', 'macro-f1', 'minority-f1'])\n",
        "    report.to_csv(OUTPUT_PATH)\n",
        "    return report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSOtQeg66aB8"
      },
      "source": [
        "## Count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8yzPXxh6aB8"
      },
      "outputs": [],
      "source": [
        "def generate_Xy(train, test, **kwargs):\n",
        "\n",
        "    main = pd.concat([train, test])\n",
        "    vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, stop_words='english', strip_accents='unicode')\n",
        "    corpus = list(main[kwargs['X_col']].str.lower())\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    main = main.join(pd.DataFrame(X.toarray()).add_prefix('count_'))\n",
        "    main.to_csv(os.path.join(MODIFIED_DATA, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/count.csv'))\n",
        "\n",
        "    vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, stop_words='english', strip_accents='unicode')\n",
        "    corpus = list(train[kwargs['X_col']].str.lower())\n",
        "    X_train = vectorizer.fit_transform(corpus)\n",
        "    X_test = vectorizer.transform(list(test[kwargs['X_col']].str.lower()))\n",
        "    X_train, y_train = csr_matrix(X_train), train[kwargs['y_col']]\n",
        "    X_test, y_test = csr_matrix(X_test), test[kwargs['y_col']]\n",
        "    non_sparse = ['gaussianNB', 'lda']\n",
        "    if(kwargs['method'] in non_sparse):\n",
        "        X_train, X_test = X_train.toarray(), X_test.toarray()\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpvVfWlV6aB8",
        "outputId": "b4d63059-e53c-4306-dd0d-0f498edce0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg done!\n",
            "knn done!\n",
            "gaussianNB done!\n",
            "bernoulliNB done!\n",
            "adaboost done!\n",
            "gradient-boosting done!\n",
            "dec-tree done!\n",
            "linear-svc done!\n",
            "c-svc done!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "results = sklearn_models(df, X_col, y_col, os.path.join(OUTPUT_DIR, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/count_vectorizer.csv'), generate_Xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kel3xdu36aB9"
      },
      "source": [
        "## Tfidf vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwobWpt_6aB9"
      },
      "outputs": [],
      "source": [
        "def generate_Xy(train, test, **kwargs):\n",
        "\n",
        "    main = pd.concat([train, test])\n",
        "    vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, stop_words='english', strip_accents='unicode')\n",
        "    corpus = list(main[kwargs['X_col']].str.lower())\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    main = main.join(pd.DataFrame(X.toarray()).add_prefix('tfidf_'))\n",
        "    main.to_csv(os.path.join(MODIFIED_DATA, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/tfidf.csv'))\n",
        "\n",
        "    vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, stop_words='english', strip_accents='unicode')\n",
        "    corpus = list(train[kwargs['X_col']].str.lower())\n",
        "    X_train = vectorizer.fit_transform(corpus)\n",
        "    X_test = vectorizer.transform(list(test[kwargs['X_col']].str.lower()))\n",
        "    X_train, y_train = csr_matrix(X_train), train[kwargs['y_col']]\n",
        "    X_test, y_test = csr_matrix(X_test), test[kwargs['y_col']]\n",
        "    non_sparse = ['gaussianNB', 'lda']\n",
        "    if(kwargs['method'] in non_sparse):\n",
        "        X_train, X_test = X_train.toarray(), X_test.toarray()\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0AF78B6aB-",
        "outputId": "96a04377-14e8-4992-fe42-e7596b4b38c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg done!\n",
            "knn done!\n",
            "gaussianNB done!\n",
            "bernoulliNB done!\n",
            "adaboost done!\n",
            "gradient-boosting done!\n",
            "dec-tree done!\n",
            "linear-svc done!\n",
            "c-svc done!\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "results = sklearn_models(df, X_col, y_col, os.path.join(OUTPUT_DIR, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/tfidf_vectorizer.csv'), generate_Xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gRvETK-6aB-"
      },
      "source": [
        "## Feature rich prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNWo4NqV6aB-"
      },
      "outputs": [],
      "source": [
        "def extract_harbingers(df, X_col):\n",
        "\n",
        "    with open('/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/lexica/2015_Diplomacy_lexicon.json') as f:\n",
        "        features = json.loads(f.readline())\n",
        "\n",
        "    for feature in features:\n",
        "        harbingers = [harbinger.encode('ascii', 'ignore').decode('ascii').lower() for harbinger in features[feature]]\n",
        "        features[feature] = harbingers\n",
        "\n",
        "    def clean_text(text):\n",
        "        text = str(text)\n",
        "        text = text.replace('\\'', '')\n",
        "        text = text.lower()\n",
        "        text = text.replace('{html}',\"\")\n",
        "        text = re.sub(re.compile('<.*?>'), '', text)\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub('[0-9]+', '', text)\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        text = \" \".join(tokens)\n",
        "        return text\n",
        "\n",
        "    def get_feature_frequency(text, feature):\n",
        "        count = 0\n",
        "        for harbinger in features[feature]:\n",
        "            count += text.count(harbinger)\n",
        "        return count\n",
        "\n",
        "    df['clean_text'] = df.apply(lambda row: clean_text(row[X_col]), axis=1)\n",
        "    for feature in features:\n",
        "        df[feature] = df.apply(lambda row: get_feature_frequency(row['clean_text'], feature), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5EGabr06aB_",
        "outputId": "33684a97-f101-4dd6-ad84-8fe965ad4211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit\n",
            "  Downloading convokit-3.0.0.tar.gz (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.2/183.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.5.3)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: spacy>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.2.2)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.1)\n",
            "Collecting dill>=0.2.9 (from convokit)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.3.2)\n",
            "Collecting clean-text>=0.6.0 (from convokit)\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit)\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (4.66.1)\n",
            "Collecting pymongo>=4.0 (from convokit)\n",
            "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from convokit) (6.0.1)\n",
            "Collecting dnspython>=1.16.0 (from convokit)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (2023.6.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->convokit) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3.5->convokit) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3.5->convokit) (0.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.3)\n",
            "Building wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.0.0-py3-none-any.whl size=216707 sha256=dfec500b9b210ffc392bfc6960938f87f681e7f3a66c9459affadcc8f488af12\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/89/8c/2677fdb888588b6f93cb6ac86bdfb020f1f1c33e0d5525b231\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=2f048f68fe3b183f9632419d9ff71c39d31ce657e380f9e18397d97e443e42c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: emoji, unidecode, msgpack-numpy, ftfy, dnspython, dill, pymongo, clean-text, convokit\n",
            "Successfully installed clean-text-0.6.0 convokit-3.0.0 dill-0.3.7 dnspython-2.4.2 emoji-1.7.0 ftfy-6.1.1 msgpack-numpy-0.4.8 pymongo-4.5.0 unidecode-1.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install convokit\n",
        "from convokit import Corpus, Speaker, Utterance\n",
        "from convokit import download\n",
        "from convokit import TextParser\n",
        "from convokit import PolitenessStrategies\n",
        "ps = PolitenessStrategies()\n",
        "spacy_nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "cols = list(ps.transform_utterance(\"hello, could you please help me proofread this article?\", spacy_nlp=spacy_nlp).meta['politeness_strategies'])\n",
        "\n",
        "def extract_politeness_feats(df, X_col):\n",
        "\n",
        "    def extract_politeness_helper(row):\n",
        "        utt = ps.transform_utterance(row[X_col], spacy_nlp=spacy_nlp)\n",
        "        feats = [utt.meta['politeness_strategies'][x] for x in cols]\n",
        "        return pd.Series(feats)\n",
        "\n",
        "    df[cols] = df.apply(extract_politeness_helper, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atz0l_1F6aB_",
        "outputId": "75fb634e-e4c6-4738-ab75-6dfb00145d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'feature_politeness_==Please=='\", \" 'feature_politeness_==Please_start=='\", \" 'feature_politeness_==HASHEDGE=='\", \" 'feature_politeness_==Indirect_(btw)=='\", \" 'feature_politeness_==Hedges=='\", \" 'feature_politeness_==Factuality=='\", \" 'feature_politeness_==Deference=='\", \" 'feature_politeness_==Gratitude=='\", \" 'feature_politeness_==Apologizing=='\", \" 'feature_politeness_==1st_person_pl.=='\", \" 'feature_politeness_==1st_person=='\", \" 'feature_politeness_==1st_person_start=='\", \" 'feature_politeness_==2nd_person=='\", \" 'feature_politeness_==2nd_person_start=='\", \" 'feature_politeness_==Indirect_(greeting)=='\", \" 'feature_politeness_==Direct_question=='\", \" 'feature_politeness_==Direct_start=='\", \" 'feature_politeness_==HASPOSITIVE=='\", \" 'feature_politeness_==HASNEGATIVE=='\", \" 'feature_politeness_==SUBJUNCTIVE=='\", \" 'feature_politeness_==INDICATIVE=='\", 'claim', 'disc_temporal_rest', 'allsubj', 'disc_expansion', 'disc_contingency', 'premise', 'disc_temporal_future', 'disc_comparison']\n"
          ]
        }
      ],
      "source": [
        "# List harbingers, liwc and politeness features\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/lexica/2015_Diplomacy_lexicon.json') as f:\n",
        "    harb_dict = json.loads(f.readline())\n",
        "#print(harb_dict)\n",
        "main_df = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/lexica/politeness_list.csv')\n",
        "X_cols = list(main_df.columns) + list(harb_dict.keys())\n",
        "print(X_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO1837mo6aCA"
      },
      "outputs": [],
      "source": [
        "def generate_Xy(train, test, **kwargs):\n",
        "    global printed\n",
        "    X_cols_filt = [x for x in X_cols if x in list(train.columns)]\n",
        "    X_cols_nf = [x for x in X_cols if x not in list(train.columns)]\n",
        "    if not printed:\n",
        "        print('[WARNING!!!] Couldnt find', X_cols_nf)\n",
        "        printed = True\n",
        "    X_train = train[X_cols_filt].to_numpy()\n",
        "    y_train = train[kwargs['y_col']]\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = test[X_cols_filt].to_numpy()\n",
        "    X_test = scaler.transform(X_test)\n",
        "    y_test = test[kwargs['y_col']]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def extract_feats(df, X_col):\n",
        "    extract_harbingers(df, X_col)\n",
        "    extract_politeness_feats(df, X_col)\n",
        "    df.to_csv(os.path.join(MODIFIED_DATA, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/harbingers_and_politeness.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-zKABER6aCA",
        "outputId": "b885a19c-d4f8-48a1-c864-54a2dca1471a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING!!!] Couldnt find [\"'feature_politeness_==Please=='\", \" 'feature_politeness_==Please_start=='\", \" 'feature_politeness_==HASHEDGE=='\", \" 'feature_politeness_==Indirect_(btw)=='\", \" 'feature_politeness_==Hedges=='\", \" 'feature_politeness_==Factuality=='\", \" 'feature_politeness_==Deference=='\", \" 'feature_politeness_==Gratitude=='\", \" 'feature_politeness_==Apologizing=='\", \" 'feature_politeness_==1st_person_pl.=='\", \" 'feature_politeness_==1st_person=='\", \" 'feature_politeness_==1st_person_start=='\", \" 'feature_politeness_==2nd_person=='\", \" 'feature_politeness_==2nd_person_start=='\", \" 'feature_politeness_==Indirect_(greeting)=='\", \" 'feature_politeness_==Direct_question=='\", \" 'feature_politeness_==Direct_start=='\", \" 'feature_politeness_==HASPOSITIVE=='\", \" 'feature_politeness_==HASNEGATIVE=='\", \" 'feature_politeness_==SUBJUNCTIVE=='\", \" 'feature_politeness_==INDICATIVE=='\"]\n",
            "logreg done!\n",
            "knn done!\n",
            "gaussianNB done!\n",
            "bernoulliNB done!\n",
            "adaboost done!\n",
            "gradient-boosting done!\n",
            "dec-tree done!\n",
            "linear-svc done!\n",
            "c-svc done!\n"
          ]
        }
      ],
      "source": [
        "printed = False\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "extract_feats(df, X_col)\n",
        "results = sklearn_models(df, X_col, y_col, os.path.join(OUTPUT_DIR, '/content/drive/MyDrive/Colab_Notebooks/deliberative-politics-main/modified_data/liwc_harbingers_politeness.csv'), generate_Xy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BfxZjME6aCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "a00e485f-98d6-49fa-bc20-309ff9143dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              method  accuracy        f1  precision  recall  macro-f1  \\\n",
              "0             logreg  0.566667  0.396667   0.366667    0.45  0.461667   \n",
              "1                knn  0.475000  0.250000   0.300000    0.25  0.388333   \n",
              "2         gaussianNB  0.641667  0.233333   0.300000    0.20  0.491667   \n",
              "3        bernoulliNB  0.616667  0.216667   0.250000    0.20  0.468333   \n",
              "4           adaboost  0.816667  0.760000   0.783333    0.80  0.760000   \n",
              "5  gradient-boosting  0.816667  0.760000   0.783333    0.80  0.760000   \n",
              "6           dec-tree  0.816667  0.760000   0.783333    0.80  0.760000   \n",
              "7         linear-svc  0.666667  0.630000   0.566667    0.75  0.605000   \n",
              "8              c-svc  0.691667  0.546667   0.566667    0.55  0.593333   \n",
              "\n",
              "   minority-f1  \n",
              "0     0.396667  \n",
              "1     0.250000  \n",
              "2     0.233333  \n",
              "3     0.216667  \n",
              "4     0.760000  \n",
              "5     0.760000  \n",
              "6     0.760000  \n",
              "7     0.630000  \n",
              "8     0.546667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-159e1081-c39e-4052-8275-2e79bc7ad8c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>macro-f1</th>\n",
              "      <th>minority-f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logreg</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.396667</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.461667</td>\n",
              "      <td>0.396667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>knn</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.388333</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaussianNB</td>\n",
              "      <td>0.641667</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bernoulliNB</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.468333</td>\n",
              "      <td>0.216667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adaboost</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gradient-boosting</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>dec-tree</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>linear-svc</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>c-svc</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.546667</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.593333</td>\n",
              "      <td>0.546667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-159e1081-c39e-4052-8275-2e79bc7ad8c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-159e1081-c39e-4052-8275-2e79bc7ad8c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-159e1081-c39e-4052-8275-2e79bc7ad8c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c4a2fc0-d3e0-4e15-b06e-84bb7666d5ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c4a2fc0-d3e0-4e15-b06e-84bb7666d5ef')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c4a2fc0-d3e0-4e15-b06e-84bb7666d5ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQaODB3NzA4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "diplomacy",
      "language": "python",
      "name": "diplomacy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}